@startuml sequence_fmri
!theme plain
skinparam backgroundColor #FEFEFE

title fMRI Pipeline - Execution Sequence

actor User
participant "submit_pipeline.py\n(RSBoldPipeline)" as Orchestrator
participant "SLURM\nScheduler" as SLURM
participant "01_validate_and_convert" as Step1
participant "02_run_fmriprep" as Step2
participant "03_denoise_signals\n(SignalDenoiser)" as Step3
participant "04_extract_roi_signals\n(ROIExtractor)" as Step4
participant "05_compute_connectivity\n(ConnectivityComputer)" as Step5
participant "05b_hippocampal_connectivity\n(HippocampalVoxelConnectivity)" as Step5b
participant "06_graph_metrics\n(GraphAnalyzer)" as Step6
participant "07_visualize_rois\n(ROIVisualizer)" as Step7
database "File System" as FS

== Initialization ==

User -> Orchestrator: python submit_pipeline.py\n--subject 01 --session 1
activate Orchestrator

Orchestrator -> Orchestrator: load_config(pipeline_config.yaml)
Orchestrator -> Orchestrator: setup_logging()
Orchestrator -> Orchestrator: create_directories()
Orchestrator -> FS: Check existing fMRIPrep derivatives
FS --> Orchestrator: derivatives status

alt fMRIPrep derivatives exist
    Orchestrator -> Orchestrator: Skip steps 1-2
else No derivatives
    == Step 1: BIDS Conversion ==
    Orchestrator -> SLURM: submit_job(validate_and_convert)
    SLURM -> Step1: Execute
    activate Step1
    Step1 -> FS: Read raw DICOM
    Step1 -> FS: Write BIDS format
    Step1 --> SLURM: Job complete
    deactivate Step1
    SLURM --> Orchestrator: job_id_1

    == Step 2: fMRIPrep ==
    Orchestrator -> SLURM: submit_job(fmriprep, depends=job_id_1)
    SLURM -> Step2: Execute (Singularity)
    activate Step2
    Step2 -> FS: Read BIDS data
    Step2 -> Step2: Preprocessing pipeline
    Step2 -> FS: Write derivatives
    Step2 --> SLURM: Job complete
    deactivate Step2
    SLURM --> Orchestrator: job_id_2
end

== Step 3: Signal Denoising ==

Orchestrator -> SLURM: submit_job(denoise, depends=fmriprep)
SLURM -> Step3: Execute
activate Step3
Step3 -> FS: Load preprocessed BOLD
Step3 -> FS: Load confounds_timeseries.tsv
Step3 -> Step3: select_confounds(6 motion + aCompCor + tCompCor)
Step3 -> Step3: denoise_signal()
Step3 -> Step3: apply_bandpass_filter(0.008-0.1 Hz)
Step3 -> Step3: motion_scrubbing(FD>0.8mm)
Step3 -> FS: Save denoised BOLD
Step3 --> SLURM: Job complete
deactivate Step3
SLURM --> Orchestrator: job_id_3

== Step 4: ROI Extraction ==

Orchestrator -> SLURM: submit_job(extract_roi, depends=job_id_3)
SLURM -> Step4: Execute
activate Step4
Step4 -> FS: Load denoised BOLD
Step4 -> Step4: load_atlas_with_template_matching()
Step4 -> Step4: validate_atlas_space()
Step4 -> Step4: NiftiLabelsMasker.fit_transform()
Step4 -> FS: Save ROI timeseries (n_rois x n_timepoints)
Step4 -> FS: Save labels file
Step4 --> SLURM: Job complete
deactivate Step4
SLURM --> Orchestrator: job_id_4

== Step 5: Connectivity Computation ==

Orchestrator -> SLURM: submit_job(connectivity, depends=job_id_4)
SLURM -> Step5: Execute
activate Step5
Step5 -> FS: Load ROI timeseries
Step5 -> Step5: ConnectivityMeasure(correlation)
Step5 -> Step5: apply_fisher_z_transform()
Step5 -> Step5: threshold_network(top 10%)
Step5 -> FS: Save connectivity matrix (CSV)
Step5 -> FS: Save companion labels file
Step5 --> SLURM: Job complete
deactivate Step5
SLURM --> Orchestrator: job_id_5

== Step 5b: Hippocampal Voxel Connectivity (Optional) ==

alt hippocampal_connectivity.enabled = true
    Orchestrator -> SLURM: submit_job(hippocampal_connectivity, depends=job_id_3)
    SLURM -> Step5b: Execute
    activate Step5b
    Step5b -> FS: Load atlas (Brainnetome/FreeSurfer)
    Step5b -> Step5b: create_hippocampal_masks()
    note right of Step5b
      Extract hippocampus labels:
      - Brainnetome: 215-218
      - FreeSurfer: 17, 53
    end note
    Step5b -> FS: Save hippocampus masks (NIfTI)

    loop for each hemisphere [left, right]
        Step5b -> FS: Load denoised BOLD
        Step5b -> Step5b: NiftiMasker.fit_transform()
        note right of Step5b
          ~500-1500 voxels
          per hemisphere
        end note
        Step5b -> Step5b: compute_voxel_connectivity_matrix()
        Step5b -> Step5b: apply_fisher_z_transform()
        Step5b -> Step5b: threshold_connectivity_matrix()
        Step5b -> Step5b: GraphMetrics.compute_all()
        Step5b -> FS: Save connectivity matrix
        Step5b -> FS: Save graph metrics (JSON)
        Step5b -> FS: Save nodal NIfTI maps
    end

    Step5b -> FS: Save summary YAML
    Step5b --> SLURM: Job complete
    deactivate Step5b
    SLURM --> Orchestrator: job_id_5b
end

== Step 6: Graph Metrics ==

Orchestrator -> SLURM: submit_job(graph_metrics, depends=job_id_5)
SLURM -> Step6: Execute
activate Step6
Step6 -> FS: Load connectivity matrix
Step6 -> Step6: GraphMetrics.compute_all()
note right of Step6
  27+ global metrics
  6 nodal metrics per ROI
end note
Step6 -> FS: Save metrics (JSON)
Step6 -> FS: Save nodal metrics (CSV)
Step6 --> SLURM: Job complete
deactivate Step6
SLURM --> Orchestrator: job_id_6

== Step 7: Visualization ==

Orchestrator -> SLURM: submit_job(visualize, depends=job_id_5)
SLURM -> Step7: Execute
activate Step7
Step7 -> FS: Load atlas + connectivity matrix
Step7 -> Step7: create_atlas_overlay()
Step7 -> Step7: create_connectivity_heatmap()
Step7 -> Step7: create_network_graph()
Step7 -> FS: Save QC images (PNG)
Step7 -> Step7: HTMLReportGenerator.generate_report()
Step7 -> FS: Save HTML report
Step7 --> SLURM: Job complete
deactivate Step7
SLURM --> Orchestrator: job_id_7

== Completion ==

Orchestrator --> User: Pipeline complete\nOutputs in data/outputs/sub-01/

deactivate Orchestrator

@enduml
